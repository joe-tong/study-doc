# MQ使用过程中的问题

- 如何保证消息重复消费
- 如何保证消息不丢失
- 消息积压问题

### 保证消息不丢失解决方案

​     关于消息丢失这个问题，现在的这些消息队列中间件只要你正确配置基本都不会丢消息，但是万一出现了这种情况，我们需要知道从哪些地方着手来解决问题.
​    一般消息丢失我们可以分为两大类：一类是网络丢失，还有一类是磁盘丢失。那么我们还是从上面的消息队列三个主要过程来分析：

A方案

```
    生产者把消息从Producer生产出来，经过网络发送给Broker端(生产阶段)：在这个阶段我们常用的保障手段就是，当Broker收到消息后给Producer一个确认响应（就是大家常说的ACK），如果Producer没有收到正确的响应，Producer直到收到Broker的确认响应后才会停止重试消息发送。这里需要注意的点是，根据自己业务场景有时候要对ACK做一些处理，消息队列大都提供了自动ACK，再需要手动确认ACK的时候我们需要关闭掉这一默认设置。还有就是需要在我们的代码处做好异常处理，尤其要注意在异步发送的回调中检查发送结果。这一就可以保证消息队列在这个阶段数据不会丢失。

```

B方案

```
   Broker收到来自Producer的消息，持久化到磁盘（存储阶段）：在这个阶段只要Broker正常工作基本上都能序列化正常，但是在集群化的Broker中发生概率还是比较高的。因此我们要对刷盘机制根据情况做一些调整，在单节点的情况下，我们可以设置当Broker接收到消息后先刷盘，当刷盘成功后再给Producer成功响应。这样即使Broker宕机，由于消息已经写入磁盘，重启后会继续处理，这里就会引入一个新的问题我们接下来会说到（消息重复）。例如设置RocketMQ中flushDiskType=SYNC_FLUSH（同步刷盘）---broker回应producer ack消息之前先刷盘
```

C方案

```
消费者通过网络，从Broker上读取消息（消费阶段）：在这个阶段我们需要注意的一定要当消费者处理完你自身业务逻辑后给Broker发送消费确认。否则当你收到消息就给Broker确认消费，此时Broker认为消费者消费成功，将消息从Broker队列中移除，当本地逻辑处理异常时就很有可能丢掉这个消息。
```

总结：

1. producer 发生消息后收到进行ack
2. broker回应producer ack消息之前先刷盘
3. 消费者一定处理完逻辑后在发确认消息

## 消息重复

​      当我们保证了不丢消息的同时，又引入了消息重复的问题 ， 其实现在解决这个问题就显得非常简单了，我们不管是生产者重复，还是Broker重复我们只要在消费端保证幂等性就可以（任意多次执行所产生的影响均与一次执行的影响相同称为幂等操作） 

 几种常用的保证幂等性的方法 ：

A方案

```
通过数据库的为唯一键实现幂等:

   我们可以在设计消息结构的时候设置一个对应数据库唯一键的列字段，业务成功后将此字段作为唯一键报错入数据库。当同样的ID做保存的时候就会出现违反数据库唯一约束异常，这里的主键可以是单独的，也可以是组合的列。这种方式可以在任何支持“INSERT IF NOT EXIST”的存储系统中适用
```

B方案

```
通过版本号/数据快照实现幂等

   其实这种方式有点类似于乐观锁的实现方式，就是需要消息中带有此业务当前一个瞬时状态的值，通过这个值与业务当前数据比较来判断是否执行更新操作。比如有一条重复的消息是这样的：将订单号为00001的状态从01变更为02（当订单00001的状态为01就改为02），这样一条重复的消息进来是不会对00001的订单做任何影响的。此时状态就是一个前置条件。再比如：将商品A的库存从500中减1（当商品A的总库存为500则减1）。类似这些需要在设计消息结构的时候带上一些业务属性活数据。另外一种办法就是给消息增加一个类似数据库的version字段，在每次消费更新的时候比较当前数据的版本号是否与消息中带的版本号一致，来判断是否执行消费。3.全局唯一ID：当一条重复的消息发送到不同的消费者时候，貌似上面的办法都不怎么管用的。这就是所谓的分布式集群中出现的重复消息并行问题，你得保证一个健壮的全局唯一发号器，然后在每次操作之前判断此ID是否已经被别的消费者消费过。当然你要没有一个健壮的全局唯一ID发号器，那么我建议你可以通过消息路由规则。将某也业务的消息存储在同一个队列主题中。（比如通过user_id，order_id将消息业务消息分发到同一个Broker的队列中，这样就既利用了集群资源，又将问题回归到上面两张处理方式了）
```

## 消息积压

​        其实对于一个原本正常的消息系统来说消息积压，只会出现两种情况：要么生产者消息数量增加导致的积压；要么就是消费者消费变慢导致的消息积压。对于一个消息队列我们肯定在上线前就预估好，单节点最大承受流量与系统目前最大峰值流量的数据，一般情况下消息队列收发性能是远大于业务处理性能的，一旦出现的话问题也很显而易见：要么就是流量突然增加，要么就是业务逻辑异常。我能应该从三个方面来查找问题：

  ```
1. 生产端：一般当生产端发生积压（Broker正常的情况下）就要查看你的业务逻辑是否有异常的耗时步骤导致的。是否需要改并行化操作等。

2. Broker端：当Broker端发生积压我们首先要查看，消息队列内存使用情况，如果有分区的的话还得看每个分区积压的消息数量差异。当每个分区的消息积压数据量相对均匀的话，我们大致可以认为是流量激增。需要在消费端做优化，或者同时需要增加Broker节点（相当于存储扩容），如果分区加压消息数量差异很大的话（有的队列满了，有的队列可能还是空闲状态），我们这时候就要检查我们的路由转发规则是否合理，

3.消费端：在使用消息队列的时候大部分的问题都出在消费端，当消费速度小于生产速度很快就会出现积压，导致消息延迟，以至于丢失。这里需要重点说明一点的是，当消费速度小于生产速度的时候，仅增加消费者是没有用处的，因为多个消费者在同一个分区上实际是单线程资源竞争关系（当然还有一些冒险的单队列多消费者并行方式就是：消费者接到消息就ack成功再去处理业务逻辑，这样你就要承受消息丢失的代价），我们需要同时增加Broker上的分区数量才能解决这一问题。
  ```

